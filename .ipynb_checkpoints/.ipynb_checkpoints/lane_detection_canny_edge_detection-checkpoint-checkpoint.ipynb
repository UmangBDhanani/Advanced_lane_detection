{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de98c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_path = 'U:/Studies/jupyter projects/test1.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(video_file_path)\n",
    "ret, frame = capture.read()\n",
    "cv2.imshow('frame',frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('frame')\n",
    "      \n",
    "# saving the image for later use using PIL and opencv\n",
    "raw_img = Image.fromarray(frame)\n",
    "im1  = raw_img.save('PIL_road_img.jpg')\n",
    "\n",
    "if os.path.exists('cv2_road_img.jpg'):\n",
    "    pass\n",
    "else:\n",
    "    filename  = 'cv2_road_img.jpg'\n",
    "    cv2.imwrite(filename, frame)\n",
    "    \n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9d3b9",
   "metadata": {},
   "source": [
    "CANNY EDGE DETECION AND HOUGH TRANSFORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes in raw image from frame and returns canny edge image\n",
    "\n",
    "def canny_conversion(img):\n",
    "  gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converting to gray scale image for processing in opencv\n",
    "  kernel_size = 5\n",
    "  blurred_img = cv2.GaussianBlur(gray_img, (kernel_size,kernel_size), 0)  # blurring the image if the image is sharp\n",
    "  canny = cv2.Canny(blurred_img, 50, 150)     # applying canny algorithm for edge detection\n",
    "  return canny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the region of interest (triangular) where the lanes can be founded and ignoring other regions\n",
    "\n",
    "def region_of_interest(image):\n",
    "  height, width = image.shape\n",
    "  mask = np.zeros_like(image)    # creating the mask of sam esize as image\n",
    "  interested_region_triangle = np.array([[(200, height), (800, 350), (1200, height)]], np.int32)    # slicing the traingle for lanes ocurence for given input image\n",
    "  cv2.fillPoly(mask, interested_region_triangle, 255)      # filling sliced triangle with white pixels and masking input image to filter out other image parts but the triangle\n",
    "  masked_image = cv2.bitwise_and(image, mask)     # filtering the input image with the mask\n",
    "  return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c337301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting the lines through hough transform for a given image and returns potential lines for the lanes\n",
    "\n",
    "def hough_transform(image):\n",
    "  hough_lines = cv2.HoughLinesP(image, 2, np.pi/180, 100, np.array([]), minLineLength = 40, maxLineGap = 50)\n",
    "  return hough_lines\n",
    "\n",
    "###################################\n",
    "#     TESTING\n",
    "output = canny_conversion(frame)\n",
    "masked_output = region_of_interest(output)\n",
    "hough_lines = cv2.HoughLinesP(image, 2, np.pi/180, 100, np.array([]), minLineLength = 40, maxLineGap = 50)\n",
    "\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33014e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns image with lines detection \n",
    "\n",
    "def display_lines(image, lines):\n",
    "  line_image = np.zeros_like(image)\n",
    "  if lines is not None:\n",
    "    for line in lines:\n",
    "      x1, y1, x2, y2 = line.reshape(4)\n",
    "      cv2.line(line_image, (x1,y1),(x2,y2),(0,0,255), 7)\n",
    "  return line_image    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(image, line_parameters):\n",
    "  slope, intercept = line_parameters\n",
    "  y1 = image.shape[0]\n",
    "  y2 = int(y1 * 3/5)\n",
    "  x1 = int((y1 - intercept) / slope)\n",
    "  x2 = int((y2-intercept) / slope)\n",
    "  \n",
    "  return np.array([x1, y1, x2, y2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the average of lines detected by hough transforms and outputs the single line. \n",
    "\n",
    "def avg_slope_intercept(image, lines):\n",
    "  left_vals = []\n",
    "  right_vals = []\n",
    "  for line in lines:\n",
    "    for x1,y1, x2, y2 in line:\n",
    "      parameters = np.polyfit((x1,x2), (y1,y2), 1)      # fit the 1st degree polynomial and output the parameters for given coordinates\n",
    "      slope = parameters[0]\n",
    "      intercept = parameters[1]\n",
    "      if slope > 0:\n",
    "        right_vals.append((slope, intercept))\n",
    "      else:\n",
    "        left_vals.append((slope, intercept))\n",
    "  \n",
    "  left_line_avg = np.average(left_vals, axis = 0)\n",
    "  right_line_avg = np.average(right_vals, axis = 0) \n",
    "  #print(left_line_avg,  'left')\n",
    "  #print(right_line_avg , 'right')\n",
    "  left_line = make_coordinates(image, left_line_avg)\n",
    "  right_line = make_coordinates(image, right_line_avg)    \n",
    "\n",
    "  return np.array([left_line, right_line])           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_file_path)\n",
    "while(cap.isOpened()):\n",
    "  _, frame = cap.read()\n",
    "  output = canny_conversion(frame)\n",
    "  masked_output = region_of_interest(output)\n",
    "  hough_lines = hough_transform(masked_output)\n",
    "  averaged_lines = avg_slope_intercept(frame, hough_lines)\n",
    "  line_image = display_lines(frame, averaged_lines)\n",
    "  final_image = cv2.addWeighted(frame,0.8, line_image, 1, 1)\n",
    "  cv2.imshow('video_output',final_image)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696750cf",
   "metadata": {},
   "source": [
    "CAMERA CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding chess board corners and claibration coefficients for camera calibration\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "def camera_calibration():\n",
    "    \"\"\"\n",
    "    \n",
    "    wrapper function to find the camera calibration coordinates through chess board corners detection\n",
    "    ideally should be perforemd on the images taken from camera that is going to be used in lane detection \n",
    "    \n",
    "    \"\"\"\n",
    "    print('starting camera calibration')\n",
    "    \n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    obj_pt = np.zeros((6 * 9, 3), np.float32)\n",
    "    obj_pt[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "    \n",
    "    chess_images = glob.glob('U:/Studies/jupyter projects/camera_cal/*')\n",
    "    nx = 9    # number of corners in x axis\n",
    "    ny = 6    # number of corners in y axis\n",
    "    \n",
    "    obj_points = []    # 3d points in real world space\n",
    "    img_points = []    # 2d points in image plane\n",
    "\n",
    "\n",
    "    for image in chess_images:\n",
    "        img = cv2.imread(image)\n",
    "        gray_image  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        det , corners = cv2.findChessboardCorners(gray_image, (nx, ny), None) \n",
    "        \n",
    "        if det :\n",
    "            img = cv2.drawChessboardCorners(img, (nx, ny), corners, det)\n",
    "            #cv2.imshow('img',img)\n",
    "            #cv2.waitKey(0)\n",
    "            obj_points.append(obj_pt)\n",
    "            img_points.append(corners)\n",
    "            \n",
    "    shape = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, _ , _ = cv2.calibrateCamera(obj_points, img_points, shape, None, None)\n",
    "    print('calibration performed')\n",
    "    #cv2.distroyAllWindows()\n",
    "    return mtx, dist\n",
    "    \n",
    "# calibration needed only once in the beginning and can be loaded in the next run form the pickle file\n",
    "if os.path.exists('camera_calib.p'):\n",
    "    with open('camera_calib.p', mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        mtx, dist = data['mtx'], data['dist']\n",
    "        print('Loaded camera calibration matrix & distortion coefficients!')\n",
    "else:\n",
    "    mtx, dist = camera_calibration()\n",
    "    with open('camera_calib.p', mode='wb') as f:\n",
    "        pickle.dump({'mtx': mtx, 'dist': dist}, f)\n",
    "    \n",
    "    \n",
    "def undistort(distorted_image, mtx, dist):\n",
    "    return cv2.undistort(distorted_image, mtx, dist, None, mtx)\n",
    "\n",
    "\n",
    "mtx , dist = camera_calibration()\n",
    "img_path = 'U:/Studies/jupyter projects/camera_cal/calibration1.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "output_image = undistort(img, mtx, dist)\n",
    "\n",
    "stacked_imgs = np.hstack((img, output_image))\n",
    "cv2.imshow('combined view', stacked_imgs)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0febf9",
   "metadata": {},
   "source": [
    "PERSPECTIVE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92c58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2GPU",
   "language": "python",
   "name": "tf2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
